{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Sentiment Analysis in Python\n",
    "## Part 1 - Downloading Twitter Data using Tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some background\n",
    "\n",
    "Late last year I had a horrible time trying to buy a Google Pixel 5 online from Currys PC World, the UK's largest electrical retailer. The phone came with a free set of Bose headphones worth £300 so I was excited to make the purchase and paid £10 extra for next day delivery. When the phone didn't arrive the next day and I hadn't heard anything, I rang Currys' customer service team to find out why.\n",
    "\n",
    "Currys' customer service team is called Team Knowhow which is ironic considering every time I called they had absolutely no idea about anything to do with my order. Each time I called I would wait about an hour on hold before someone different would answer and give a different reason for what had happened and why my order hadn't been delivered. The person would then tell me that I would be called back within 24-48 hours to resolve the issue, which of course never happened, forcing me to call back, wait on hold again and have the whole process repeat multiple times.\n",
    "\n",
    "After a week of calling and still with no phone, I was frustrated and searched online for other ways to contact Team Knowhow. I first found an email address so I sent all my details but never got a reply. To be fair, eventually I did get a reply but it only arrived last week, nearly 3 months to the day from when I had sent my first email. \n",
    "\n",
    "I also found Team Knowhow's Twitter account which had lots of activity back and forth between customers and the Team Knowhow customer support team. I've had a Twitter account for years but apart from tweeting to enter the occasional competition, I've never really used it other than a source of news and information. I noticed others having the same issue as me so I tweeted for help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">I paid for a <a href=\"https://twitter.com/Google?ref_src=twsrc%5Etfw\">@Google</a> Pixel 5 online from <a href=\"https://twitter.com/curryspcworld?ref_src=twsrc%5Etfw\">@curryspcworld</a> which was available for next day delivery and they haven&#39;t delivered. They have taken my money but won&#39;t tell me when it will be back in stock. <a href=\"https://twitter.com/TeamKnowhowUK?ref_src=twsrc%5Etfw\">@TeamKnowhowUK</a> isn&#39;t responding to my calls or emails. Very frustrating.</p>&mdash; Cameron McLean (@cammclean182) <a href=\"https://twitter.com/cammclean182/status/1319898794830536705?ref_src=twsrc%5Etfw\">October 24, 2020</a></blockquote>\n",
       "<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import requests\n",
    "from IPython.display import HTML\n",
    "response = requests.get('https://publish.twitter.com/oembed?url=https://twitter.com/cammclean182/status/1319898794830536705')\n",
    "html = response.json()[\"html\"]\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@TeamKnowhowUK replied pretty much straight away and asked me to direct message them more information so they could look into it. Unfortunately it turned out the Team Knowhow service on Twitter wasn't any better than the Team Knowhow service via phone. After I sent them all the information, they would say they were looking into it and then never respond to any future messages sent via DM. Each time I followed up for an update my messages got ignored. I'd then tweet again publicly which would get an immediate response, again asking me to DM them my information which would then get ignored and the process would repeat.\n",
    "\n",
    "I was more than frustrated and tweeted them to let them know how I felt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">I love how <a href=\"https://twitter.com/TeamKnowhowUK?ref_src=twsrc%5Etfw\">@TeamKnowhowUK</a> ask you to DM them for &#39;privacy reasons&#39; but when you do they still don&#39;t respond or resolve your issues. It seems like they want to appear to help but really they just want people to contact them privately where the public can&#39;t see them ignore you.</p>&mdash; Cameron McLean (@cammclean182) <a href=\"https://twitter.com/cammclean182/status/1320332221530648576?ref_src=twsrc%5Etfw\">October 25, 2020</a></blockquote> <script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To cut a long story short, there's some truth in the proverb about the squeaky wheel getting the grease. After tweeting publicly a few times to highlight @TeamKnowhowUK's terrible customer service, there was eventually a happy ending and my new phone was delivered a few weeks later. I never received an explanation about what had happened with my order but from other complaints I've read online, it looks like Currys' online store struggles to keep track of what's in stock and has a long history of selling out of stock items they can't deliver. Despite the happy ending I made a promise to myself that i'd never shop at Currys again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So what's this got to do with Sentiment Analysis in Python?\n",
    "\n",
    "Recently I've been experimenting with some sentiment analysis libraries in Python. Sentiment analysis, or opinion mining, refers to the use of natural language processing to systematically analyse large quantities of unstructured text and identify whether the text has positive, negative or neutral sentiment. \n",
    "\n",
    "Sentiment analysis is commonly used by businesses to conduct market research and analyse how products, competitors or customer support are perceived by the market. I've also read it's used by quantitative hedge funds who have incorporated sentiment analysis into trading strategies. I was keen to understand the process better to then see how I could apply it to my own trading strategies.\n",
    "\n",
    "A common source of data for sentiment analysis is Twitter which led me to expirement with some libraries used for downloading Twitter data, mainly Tweepy and Twint. When looking for data to analyse, I remembered my experience with Team Knowhow and the negative sentiment I saw in all the tweets from unhappy customers. I wondered whether the sentiment analysis libraries would report the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twitter Data Libraries - Twint vs Tweepy\n",
    "\n",
    "To download data from Twitter there seems to be two main Python libraries - [Twint](https://github.com/twintproject/twint) and [Tweepy](https://www.tweepy.org/).\n",
    "\n",
    "I first started using Tweepy which uses Twitter's official API to access and download data. It requires you to apply for developer access to get keys from Twitter to use their API which is relatively quick and painless. As the library has been around for over 10 years, the documentation is great and there are plenty of tutorials online for learning how to use the package.\n",
    "\n",
    "The main advantage of using Tweepy is that it uses the official Twitter API. This enables much more functionality than just downloading tweets. You can post tweets, block people, send DMs and write scripts to automatically retweet or follow back people who follow you. \n",
    "\n",
    "The biggest limitation of Tweepy is also that it uses the official Twitter API. The API limits the amount of data that can be downloaded and with the free account you are limited to downloading a few thousand tweets from within the last 7 days. This is great for obtaining recent data but for some of the trading ideas I wanted to explore, I would need tweet data going back further in history to conduct proper backtests.\n",
    "\n",
    "Twint is a much younger library and the documentation is somewhat minimal. It doesn't use the official Twitter API to obtain data but rather scrapes Twitter from public webpage addresses. Once you get it installed correctly (see below), its performance seems to be on par with Tweepy and it downloads data just as quick. It's never going to be as fast as using the offical API but its biggest advantage from not using the API is that you can effectively download tweets going back as far as you want, without any rate limitations.\n",
    "\n",
    "Both libraries are popular and work well but Twint has recently taken the lead in Github stars, I assume from data hungry scientists looking to obtain tweet data older than the last 7 days.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images\\starhistory.png\">\n",
    "<div style=\"text-align: center\"> Github Star History: https://star-history.t9t.io/#twintproject/twint&tweepy/tweepy </div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation of Twint\n",
    "\n",
    "Despite online installation instructions advising a simple `pip install twint` to install Twint via PyPI's repository, I immediately ran into issues trying to use the library. It looked like Twitter had removed one of the endpoints that Twint used to make searches. \n",
    "\n",
    "Googling for solutions, I found the issue being discussed on [Twint's github repo](https://github.com/twintproject/twint/issues/915) and one of the contributors Himanshu Dabas providing a workaround that could be installed directly from Twint's github repo:\n",
    "\n",
    "`pip install --upgrade git+https://github.com/twintproject/twint.git@origin/master#egg=twint`\n",
    "\n",
    "Note if you are using Windows you'll also need Microsoft's C++ build tools to be installed.\n",
    "\n",
    "To use Twint in Jupyter notebooks you also need to install nest asyncio by:\n",
    "\n",
    "`pip install nest_asyncio`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching Twitter using Twint\n",
    "\n",
    "Before using Twint you need to import the twint and nest_asyncio libraries and then apply nest_asynicio to allow event loops to be nested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import twint\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once eveything is imported you need to specify your configuration parameters for the search function.\n",
    "\n",
    "There's dozen of options that allow you to make your searches as simple or complex as required. You can search for tweets containing a specific keyword or username and you can use combinations of multiple paramaters to do complex searches such as finding tweets with a specific keyword that have more than 100 likes and were tweeted from a specific location on a specific date. \n",
    "\n",
    "There's also configuration options to specify how you want to store the results, whether that be in a JSON file, CSV or SQLite Database. \n",
    "\n",
    "A full set of configuration options can be found on [Twint's Github Wiki](https://github.com/twintproject/twint/wiki/Configuration)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# twint configuration\n",
    "c = twint.Config()\n",
    "\n",
    "c.Search = 'teamknowhowuk'\n",
    "\n",
    "c.Since = '2020-10-01 00:00:00' #\"2020-10-01 00:00:00\"\n",
    "c.Until = '2020-10-02 00:00:00' #\"2020-11-01 00:00:00\"\n",
    " \n",
    "c.Hide_output = True\n",
    "\n",
    "c.Store_json = True\n",
    "c.Output = '../data/twint_search_data.json' #outpath "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above I used the 'since' and 'until' configuration paramaters to search for tweets in October 2020. Despite the docs saying otherwise, I found that the dates had to be passed in using the following format '%Y-%m-%d %H:%M:%S'.\n",
    "\n",
    "I've also set Hide_output to True to hide the scraper showing each tweet as it searches which quickly fills up the window when doing the search in Jupyter notebooks.\n",
    "\n",
    "Once you have specified the configuration paramaters, they can then be passed into the Search function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'Path' has no attribute 'PurePath'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-0483da28d5e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mPath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPurePath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'test.json'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: type object 'Path' has no attribute 'PurePath'"
     ]
    }
   ],
   "source": [
    "Path.PurePath('data','test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/camer/Projects/twitter_sentiment/data/example_data.json'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "outpath = (Path.cwd().parent / 'data' / 'example_data.json').as_posix()\n",
    "outpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n"
     ]
    }
   ],
   "source": [
    "# run search\n",
    "twint.run.Search(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above search took approx 3 minutes to return 22000 tweets that matched my search paramaters. For reference the json file is approx 21mb. \n",
    "\n",
    "The search time depends on your search paramaters and I assume somewhat on your internet connection. For 22000 tweets I don't think 3 minutes it too bad.\n",
    "\n",
    "Note if you run this search twice, it adds to the existing JSON rather than creating a new file. There must be a setting to create a new file but I haven't found it yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posts\n",
    "\n",
    "Here;s where i write about interesting thigns to me. Tutorials for things i've done that others might want to copy. Look at why i write link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first person\n",
    "\n",
    "taghs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary Post - all code in one\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TLDR:\n",
    "- Twint allows you to scrape Twitter data for analysis in Python\n",
    "- Vader, Textblog are open source libraries that allow you to perform sentiment analysis in Python\n",
    "- From my analysis of Currys customer service twitter account @Teamknowhowuk:\n",
    "  - % of tweets have negative sentiment (insert chart?)\n",
    "  - Y% of the time, teakknowhow ask the compliant tweeting to dm them\n",
    "  - theres x people signing off which implies how many perope responding to how many.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing the results\n",
    "\n",
    "To view the results in a dataframe, I import the json file using pandas. Note the lines paramater needs to be set to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "df =  pd.read_json('data/tweets/exampleoutput.json', lines = True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Twint returns multiple columns of data that can then be used for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example a specific tweets URL can be used to display the tweet using the requests and iptyhon libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import requests\n",
    "from IPython.display import HTML\n",
    "\n",
    "url = 'https://publish.twitter.com/oembed?url=' + df[df['id']==1319898794830536705]['link'].values[0]\n",
    "response = requests.get(url)\n",
    "html = response.json()[\"html\"]\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its also easy to see who has tweeted the most, who has the most liked tweet or most retweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get top 10 most frequent usernames\n",
    "df['username'].value_counts()[:10].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching within a Loop\n",
    "\n",
    "I found when doing very large searches (such as searching for a whole's year of tweets for a  common keyword) often something would go wrong and the search would crash/freeze. The whole point of using Twint (over Tweepy) was to access large amounts of data and not be restricted by Twitters API limits so having it crash on large searches was not ideal.\n",
    "\n",
    "To avoid these issues I had better results searching each day at a time in a loop and then saving individual json files that could be imported and combined into one dataframe. A special mention to Neal Caren here who took a similar approach and inspired my code.\n",
    "\n",
    "First I create a function to do a twint search and then a function to loop over the search function for each day in a date range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required packages\n",
    "import datetime as dt\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "def twint_search(search_term, since, until, save_path):\n",
    "    c = twint.Config()\n",
    "    c.Search = search_term\n",
    "    c.Lang = \"en\"\n",
    "    c.Since = since.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    c.Until = until.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    c.Hide_output = True\n",
    "    c.Store_json = True\n",
    "    c.Output = save_path\n",
    "    twint.run.Search(c)\n",
    "    \n",
    "def twint_search_loop(search_term, start_date, end_date, save_dir):\n",
    "    try:\n",
    "        os.makedirs(os.path.join(os.getcwd(),save_dir,search_term))\n",
    "        print(f'Successfully created the directory {os.path.join(os.getcwd(),save_dir,search_term)}')\n",
    "    except FileExistsError:\n",
    "        print(f'Directory {os.path.join(os.getcwd(),save_dir,search_term)} already exists')\n",
    "    \n",
    "    date_range = pd.date_range(start_date, end_date)\n",
    "    \n",
    "    for single_date in date_range:\n",
    "        since = single_date\n",
    "        until = single_date + dt.timedelta(days=1)\n",
    "        save_path = os.path.join(save_dir, search_term, f'{single_date:%Y%m%d}.json')\n",
    "        print(f\"Searching for tweets containing '{search_term}' from {single_date:%Y-%m-%d} and saving into {save_path}\")\n",
    "        twint_search(search_term, since, until, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's search for every tweet containing 'teamknowhowuk' during 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_term = 'teamknowhowuk'\n",
    "start_date = dt.datetime(2020, 10, 1)\n",
    "end_date = dt.datetime(2020, 10, 31)\n",
    "save_dir = 'data/tweets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twint_search_loop(search_term, start_date, end_date, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve paths recursively from inside the saved directory\n",
    "json_files = glob(os.path.join(save_dir, search_term, '*.json'))\n",
    "\n",
    "# Create dataframes for each json file and combine into a single df\n",
    "dfs = [pd.read_json(json_file, lines = True) for json_file in json_files]\n",
    "tweets_df = pd.concat(dfs).reset_index(drop=True)\n",
    "tweets_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So same result - now have the flexibility to run for longer periods (twitter has data going back to 200X) and only import the JSON for one day and creating code before running on the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new dataframe to use in sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df = tweets_df[['id', 'created_at', 'username', 'tweet','likes_count']].copy()\n",
    "analysis_df[\"created_at\"] = pd.to_datetime(analysis_df[\"created_at\"], utc=True)\n",
    "\n",
    "print(analysis_df.info())\n",
    "display(analysis_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_tweet(tweet):\n",
    "    tweet=re.sub(r\"http\\S+\", \"\", tweet) #remove urls\n",
    "    tweet=re.sub(r'\\S+\\.com\\S+','',tweet) #remove urls\n",
    "    tweet=re.sub(r'\\@\\w+','',tweet) #remove mentions\n",
    "    tweet=re.sub(r'\\#\\w+','',tweet) #remove hashtags\n",
    "    return tweet\n",
    "\n",
    "analysis_df['cleaned_tweet']=analysis_df['tweet'].apply(lambda x: clean_tweet(x))\n",
    "analysis_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vader Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "analysis_df['vader_neg'] = analysis_df['cleaned_tweet'].apply(lambda x:analyzer.polarity_scores(x)['neg'])\n",
    "analysis_df['vader_neu'] = analysis_df['cleaned_tweet'].apply(lambda x:analyzer.polarity_scores(x)['neu'])\n",
    "analysis_df['vader_pos'] = analysis_df['cleaned_tweet'].apply(lambda x:analyzer.polarity_scores(x)['pos'])\n",
    "analysis_df['vader_compound'] = analysis_df['cleaned_tweet'].apply(lambda x:analyzer.polarity_scores(x)['compound'])\n",
    "analysis_df['vader_sentiment'] =['positive' if score > 0.05 else 'negative' if score < -0.05 else 'neutral' for score in analysis_df['vader_compound']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_display = ['username','cleaned_tweet', 'vader_compound', 'vader_sentiment']\n",
    "analysis_df[columns_to_display].sort_values(by=\"vader_compound\",ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "immediately clear daviddurbin9 tweet not picked up correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "analysis_df['textblob_polarity'] = analysis_df['cleaned_tweet'].apply(lambda x: TextBlob(x).sentiment[0])\n",
    "analysis_df['textblob_subjectivity'] = analysis_df['cleaned_tweet'].apply(lambda x: TextBlob(x).sentiment[1])\n",
    "analysis_df['textblob_sentiment'] = ['positive' if score > 0 else 'negative' if score < 0 else 'neutral' for score in analysis_df['textblob_polarity']]\n",
    "\n",
    "columns_to_display = ['username','cleaned_tweet', 'textblob_polarity', 'textblob_subjectivity', 'textblob_sentiment']\n",
    "analysis_df[columns_to_display].sort_values(by=\"textblob_polarity\",ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df['user'] = ['teamknowhowuk' if name == 'teamknowhowuk' else 'public' for name in analysis_df['username']]\n",
    "analysis_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = analysis_df.groupby([\"user\"])[\"textblob_sentiment\"].value_counts().unstack()\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add total for first chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.loc['public']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary['negative'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "negative = go.Bar(\n",
    "    #x = 'Total',\n",
    "    y = summary['negative'].sum(),\n",
    "    name = \"Negative\",\n",
    ")\n",
    "\n",
    "neutral = go.Bar(\n",
    "    #x = 'Total',\n",
    "    y = summary['neutral'].sum(),\n",
    "    name = \"neutral\",\n",
    ")\n",
    "\n",
    "positive = go.Bar(\n",
    "    #x = 'Total',\n",
    "    y = summary['positive'].sum(),\n",
    "    name = \"positive\",\n",
    ")\n",
    "\n",
    "layout = go.Layout(width=1000, height=600)\n",
    "\n",
    "data = [negative, neutral, positive]\n",
    "\n",
    "fig = go.Figure(data=data,layout=layout)\n",
    "fig.update_layout(barmode='group')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "negative = go.Bar(\n",
    "    x = summary.index,\n",
    "    y = summary['negative'],\n",
    "    name = \"Negative\",\n",
    ")\n",
    "\n",
    "neutral = go.Bar(\n",
    "    x = summary.index,\n",
    "    y = summary['neutral'],\n",
    "    name = \"neutral\",\n",
    ")\n",
    "\n",
    "positive = go.Bar(\n",
    "    x = summary.index,\n",
    "    y = summary['positive'],\n",
    "    name = \"positive\",\n",
    ")\n",
    "\n",
    "layout = go.Layout(width=1000, height=600)\n",
    "\n",
    "data = [negative, neutral, positive]\n",
    "\n",
    "fig = go.Figure(data=data,layout=layout)\n",
    "fig.update_layout(barmode='group')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df[analysisa_df['username']!='teamknowhowuk']['textblob_sentiment'].value_counts()\n",
    "analysis_df[analysis_df['username']=='teamknowhowuk']['textblob_sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df = pd.pivot_table(analysis_df, index=['user'])\n",
    "                            #values='textblob_sentiment', index=['user'], columns=['textblob_sentiment'], aggfunc='count')\n",
    "summary_df\n",
    "#analysis_df.groupby(['user','textblob_sentiment'])['textblob_sentiment'].count()\n",
    "#display(summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure(\n",
    "    [go.Bar(\n",
    "        x=analysis_df[analysis_df['username']!='teamknowhowuk']['textblob_sentiment'].value_counts().index,\n",
    "        y=analysis_df[analysis_df['username']!='teamknowhowuk']['textblob_sentiment'].value_counts(),\n",
    "    )]\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### import plotly.graph_objects as go\n",
    "\n",
    "data = go.Histogram(x=analysis_df['textblob_polarity'],nbinsx=21)\n",
    "layout = go.Layout(width=1000, height=600)\n",
    "\n",
    "fig = go.Figure(data=data,layout=layout)\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "public = go.Histogram(x=analysis_df[analysis_df['username']!='teamknowhowuk']['textblob_polarity'],nbinsx=20,name='public')\n",
    "teamknowhowuk = go.Histogram(x=analysis_df[analysis_df['username']=='teamknowhowuk']['textblob_polarity'],nbinsx=20, name='teamknowhow')\n",
    "layout = go.Layout(width=1000, height=600)\n",
    "\n",
    "data = [public, teamknowhowuk]\n",
    "fig = go.Figure(data=data,layout=layout)\n",
    "fig.update_layout(barmode='overlay')\n",
    "fig.update_traces(opacity=0.75)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import textwrap\n",
    "\n",
    "teamknowhowuk = go.Scatter(\n",
    "    x=analysis_df[analysis_df['username']=='teamknowhowuk']['textblob_polarity'], \n",
    "    y=analysis_df[analysis_df['username']=='teamknowhowuk']['textblob_subjectivity'],\n",
    "    mode='markers', name='teamknowhowuk', marker_color='fuchsia', opacity=0.5,\n",
    "    hoverinfo=\"text\", hovertext = analysis_df[analysis_df['username']=='teamknowhowuk']['tweet'].apply(lambda txt: '<br>'.join(textwrap.wrap(txt, width=50))),\n",
    ")\n",
    "\n",
    "public = go.Scatter(\n",
    "    x=analysis_df[analysis_df['username']!='teamknowhowuk']['textblob_polarity'], \n",
    "    y=analysis_df[analysis_df['username']!='teamknowhowuk']['textblob_subjectivity'],\n",
    "    mode='markers', name='public', marker_color='turquoise', opacity=0.75,\n",
    "    hoverinfo=\"text\", hovertext = analysis_df[analysis_df['username']!='teamknowhowuk']['tweet'].apply(lambda txt: '<br>'.join(textwrap.wrap(txt, width=50))),\n",
    ")\n",
    "\n",
    "layout = go.Layout(\n",
    "    title='Textblob Sentiment Analysis',\n",
    "    width=1000, height=600,\n",
    "    template='seaborn',\n",
    "    xaxis_title='<--- Negative Sentiment                 Positive Sentiment --->',\n",
    "    yaxis_title='<--- Objective / Facts               Subjective / Opinions --->',\n",
    "    hoverlabel_align = 'right',\n",
    "    legend = {'yanchor': 'bottom', 'y': 1, 'xanchor': 'right', 'x': 1, 'orientation': 'h'},\n",
    "    margin=dict(l=60, r=60, b=60, t=75),\n",
    "    xaxis_range= [-1.025,1.025], yaxis_range= [-0.025,1.025]\n",
    ")\n",
    "\n",
    "data = [teamknowhowuk, public]\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "#fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "textwrap.shorten(\"Hello  world!\", width=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "afinn = Afinn() #afinn = Afinn(emoticons=True)\n",
    "analysis_df['afinn_score'] = analysis_df['tweet'].apply(afinn.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df.sort_values(by=\"vader_compound\",ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df[columns_to_display].sort_values(by=\"vader_compound\",ascending=True).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df[analysis_df['username']=='teamknowhowuk'][columns_to_display].sort_values(by=\"vader_compound\",ascending=True).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df[analysis_df.duplicated(['tweet'])].drop_duplicates(subset=['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Five user who got most frequent like\n",
    "analysis_df.sort_values(by=\"likes_count\",ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df['vader_compound'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df[columns_to_display].groupby(['username']).sum().sort_values(by=\"vader_compound\",ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df[analysis_df['username']=='joyfulbrand']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "data = go.Histogram(x=analysis_df['vader_compound'],nbinsx=20)\n",
    "layout = go.Layout(width=1000, height=600)\n",
    "fig = go.Figure(data=data,layout=layout)\n",
    "\n",
    "fig.show()\n",
    "\n",
    "public = go.Histogram(x=analysis_df[analysis_df['username']!='teamknowhowuk']['vader_compound'],nbinsx=20,name='public')\n",
    "teamknowhowuk = go.Histogram(x=analysis_df[analysis_df['username']=='teamknowhowuk']['vader_compound'],nbinsx=20, name='teamknowhow')\n",
    "layout = go.Layout(width=1000, height=600)\n",
    "\n",
    "data = [public, teamknowhowuk]\n",
    "fig = go.Figure(data=data,layout=layout)\n",
    "fig.update_layout(barmode='overlay')\n",
    "fig.update_traces(opacity=0.75)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public = go.Histogram(x=analysis_df[analysis_df['username']!='teamknowhowuk']['vader_compound'],nbinsx=20,name='public')\n",
    "teamknowhowuk = go.Histogram(x=analysis_df[analysis_df['username']=='teamknowhowuk']['vader_compound'],nbinsx=20, name='teamknowhow')\n",
    "layout = go.Layout(width=1000, height=600)\n",
    "\n",
    "data = [public, teamknowhowuk]\n",
    "fig = go.Figure(data=data,layout=layout)\n",
    "fig.update_layout(barmode='overlay')\n",
    "fig.update_traces(opacity=0.75)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a document\n",
    "all_words = ' '.join([tweet for tweet in analysis_df['cleaned_tweet']])\n",
    "# Create a WordCloud object\n",
    "wordCloud = WordCloud(background_color='black', \n",
    "                      width=800, height=300,\n",
    "                      random_state=21, max_font_size=110,\n",
    "                      max_words=200, \n",
    "                      contour_color='black', \n",
    "                      contour_width=1).generate(all_words)\n",
    "# Plot WordCloud object\n",
    "plt.figure(figsize=[8,8])\n",
    "plt.imshow(wordCloud, interpolation=\"bilinear\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TextBlob('this is a test message i really like but find terrible to use').sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.polarity_scores('this is a test message i really like but find terrible to use')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df['textblob_polarity'] = analysis_df['tweet'].apply(textblob_sentiment).apply(lambda x: x[0])\n",
    "analysis_df['textblob_subjectivity'] = analysis_df['tweet'].apply(textblob_sentiment).apply(lambda x: x[1])\n",
    "analysis_df['textblob_sentiment'] = ['positive' if score > 0 else 'negative' if score < 0 else 'neutral' for score in analysis_df['textblob_polarity']]\n",
    "\n",
    "\n",
    "afinn = Afinn() #afinn = Afinn(emoticons=True)\n",
    "analysis_df['afinn_score'] = analysis_df['tweet'].apply(afinn.score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Now i looked at sentiment - vader vs texblog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = TextBlob('love  service')\n",
    "print(test.sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://textblob.readthedocs.io/en/dev/quickstart.html\n",
    "\n",
    "The sentiment property returns a namedtuple of the form Sentiment(polarity, subjectivity). \n",
    "\n",
    "The polarity score is a float within the range [-1.0, 1.0]. \n",
    "\n",
    "The subjectivity is a float within the range [0.0, 1.0] where 0.0 is very objective and 1.0 is very subjective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "def textblob_sentiment(text):\n",
    "    try:\n",
    "        return TextBlob(text).sentiment\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "analysis_df['textblob_polarity'] = analysis_df['tweet'].apply(textblob_sentiment).apply(lambda x: x[0])\n",
    "analysis_df['textblob_subjectivity'] = analysis_df['tweet'].apply(textblob_sentiment).apply(lambda x: x[1])\n",
    "analysis_df['textblob_sentiment'] = ['positive' if score > 0 else 'negative' if score < 0 else 'neutral' for score in analysis_df['textblob_polarity']]\n",
    "analysis_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df['textblob_sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df[analysis_df['username']=='teamknowhowuk']['textblob_sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df[analysis_df['username']!='teamknowhowuk']['textblob_sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df['vader_neg'] = analysis_df['tweet'].apply(lambda x:analyzer.polarity_scores(x)['neg'])\n",
    "analysis_df['vader_neu'] = analysis_df['tweet'].apply(lambda x:analyzer.polarity_scores(x)['neu'])\n",
    "analysis_df['vader_pos'] = analysis_df['tweet'].apply(lambda x:analyzer.polarity_scores(x)['pos'])\n",
    "analysis_df['vader_compound'] = analysis_df['tweet'].apply(lambda x:analyzer.polarity_scores(x)['compound'])\n",
    "analysis_df['vader_sentiment'] =['positive' if score > 0.05 else 'negative' if score < -0.05 else 'neutral' for score in analysis_df['vader_compound']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df['vader_sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df[analysis_df['username']=='teamknowhowuk']['vader_sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df[analysis_df['username']!='teamknowhowuk']['vader_sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install afinn\n",
    "#https://github.com/fnielsen/afinn\n",
    "from afinn import Afinn\n",
    "afinn = Afinn() #afinn = Afinn(emoticons=True)\n",
    "analysis_df['afinn_score'] = analysis_df['tweet'].apply(afinn.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df['afinn_score'] = analysis_df['tweet'].apply(afinn.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df[analysis_df['username']=='teamknowhowuk'].sort_values(by='afinn_score')[columns_to_display].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_display = ['tweet', 'afinn_score']\n",
    "analysis_df.sort_values(by='afinn_score')[columns_to_display].tail(10)\n",
    "#analysis_df.sort_values(by='afinn_score').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df[(analysis_df['textblob_sentiment'] == 'positive')&(analysis_df['vader_sentiment'] == 'negative')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df[(analysis_df['textblob_sentiment']=='positive') & (analysis_df['vader_sentiment']=='positive') & ~(analysis_df['username']=='teamknowhowuk')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df['vader_compound'].idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df.groupby('vader_sentiment').count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x = ['Negative', 'Neutral', 'Positive'],\n",
    "    y = [8, 12, 4],\n",
    "    color = ['red','blue','green']\n",
    "    name = \"Textblob\",\n",
    "))\n",
    "\n",
    "#fig.add_trace(go.Bar(\n",
    "#    x = ['Negative', 'Neutral', 'Positive'],\n",
    "#    y = [5, 10, 5],\n",
    "#    name = \"Vader\",\n",
    "#))\n",
    "\n",
    "fig.update_layout(title_text=\"Multi-category axis\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "  x = [['Vader', 'Vader', 'Textblob', 'Textblob'],\n",
    "       [\"A\", \"A\", \"A\", \"A\"]],\n",
    "  y = [2, 3, 1, 5],\n",
    "  name = \"Neutral\",\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "  x = [['Vader', 'Vader', 'Textblob', 'Textblob'],\n",
    "       [\"A\", \"A\", \"A\", \"A\"]],\n",
    "  y = [8, 3, 6, 5],\n",
    "  name = \"Negative\",\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "  x = [['Vader', 'Vader', 'Textblob', 'Textblob'],\n",
    "       [\"A\", \"A\", \"A\", \"A\"]],\n",
    "  y = [8, 3, 6, 5],\n",
    "  name = \"Positive\",\n",
    "))\n",
    "\n",
    "fig.update_layout(title_text=\"Multi-category axis\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=analysis_df['vader_sentiment']))\n",
    "fig.add_trace(go.Histogram(x=analysis_df['textblob_sentiment']))\n",
    "#fig.add_trace(go.Histogram(x=\"textblob_sentiment\"))\n",
    "fig.update_xaxes(categoryorder='array', categoryarray= ['negative','neutral','positive'])\n",
    "# Overlay both histograms\n",
    "#fig.update_layout(barmode='overlay')\n",
    "# Reduce opacity to see both histograms\n",
    "fig.update_traces(opacity=0.75)\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.histogram(analysis_df, x=\"vader_sentiment\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manually validate scores - vader handles text better as does emoticons? https://stackoverflow.com/questions/47760662/sentiment-analysis-in-python-textblob-vs-vader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.polarity_scores(analysis_df['tweet'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df['tweet'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.polarity_scores('so how long exactly do I have to wait to find out where the printer I ordered 3 weeks ago has gone? No printer, no refund, no communication')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df['textblob_polarity'] = analysis_df['tweet'].apply(textblob_sentiment).apply(lambda x: x[0])\n",
    "analysis_df['textblob_subjectivity'] = analysis_df['tweet'].apply(textblob_sentiment).apply(lambda x: x[1])\n",
    "analysis_df['textblob_sentiment'] = ['positive' if score > 0 else 'negative' if score < 0 else 'neutral' for score in analysis_df['textblob_polarity']]\n",
    "analysis_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "need to reindex?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#textblob_sentiment = ['positive' if score > 0 else 'negative' if score < 0 else 'neutral' for score in analysis_df['textblob_polarity']]\n",
    "#textblob_sentiment\n",
    "analysis_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "fig = go.Figure(data=[go.Histogram(x=analysis_df['textblob_polarity'])])\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "x0 = np.random.randn(500)\n",
    "# Add 1 to shift the mean of the Gaussian distribution\n",
    "x1 = np.random.randn(500) + 1\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=x0))\n",
    "fig.add_trace(go.Histogram(x=x1))\n",
    "\n",
    "# Overlay both histograms\n",
    "fig.update_layout(barmode='overlay')\n",
    "# Reduce opacity to see both histograms\n",
    "fig.update_traces(opacity=0.75)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Polarity]     = df[TEXT].apply(sentiment).apply(lambda x: x[0])\n",
    "df['Subjectivity] = df[TEXT].apply(sentiment).apply(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_polarity(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "analysis_df['Polarity'] = analysis_df['tweet'].apply(get_polarity)\n",
    "\n",
    "analysis_df['Sentiment']='NEUTRAL'\n",
    "analysis_df.loc[analysis_df.Polarity>0.25,'Sentiment']='POSITIVE'\n",
    "analysis_df.loc[analysis_df.Polarity<-0.25,'Sentiment']='NEGATIVE'\n",
    "\n",
    "analysis_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df[analysis_df['username']=='teamknowhowuk']['Sentiment'].value_counts().plot(kind='bar',title=\"Sentiment Analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df[analysis_df['username']!='teamknowhowuk']['Sentiment'].value_counts().plot(kind='bar',title=\"Sentiment Analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df[analysis_df['username']!='teamknowhowuk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "df2['textblog_sent'] = df['tweet'].apply(lambda tweet: TextBlob(tweet).sentiment)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_polarity(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "analysis_df['scores'] = analysis_df['tweet'].apply(lambda tweet: sid.polarity_scores(tweet))\n",
    "\n",
    "analysis_df['compound']  = analysis_df['scores'].apply(lambda score_dict: score_dict['compound'])\n",
    "\n",
    "analysis_df['vader_sentiment_type']='NEUTRAL'\n",
    "analysis_df.loc[analysis_df.compound>0.25,'vader_sentiment_type']='POSITIVE'\n",
    "analysis_df.loc[analysis_df.compound<-0.25,'vader_sentiment_type']='NEGATIVE'\n",
    "\n",
    "analysis_df.sample(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df[analysis_df['username']!='teamknowhowuk']['vader_sentiment_type'].value_counts().plot(kind='bar',title=\"Sentiment Analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df[analysis_df['username']=='teamknowhowuk']['vader_sentiment_type'].value_counts().plot(kind='bar',title=\"Sentiment Analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Create a function to get the subjectivity\n",
    "def getSubjectivity(text):\n",
    "   return TextBlob(text).sentiment.subjectivity\n",
    "\n",
    "# Create a function to get the polarity\n",
    "def getPolarity(text):\n",
    "   return  TextBlob(text).sentiment.polarity\n",
    " \n",
    "\n",
    "# Create two new columns 'Subjectivity' & 'Polarity'\n",
    "df2['Subjectivity'] = df2['tweet'].apply(getSubjectivity)\n",
    "df2['Polarity'] = df2['tweet'].apply(getPolarity)\n",
    "\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "scores = []\n",
    "# Declare variables for scores\n",
    "compound_list = []\n",
    "positive_list = []\n",
    "negative_list = []\n",
    "neutral_list = []\n",
    "for i in range(df2['tweet'].shape[0]):\n",
    "#print(analyser.polarity_scores(sentiments_pd['text'][i]))\n",
    "    compound = analyzer.polarity_scores(df2['tweet'][i])[\"compound\"]\n",
    "    pos = analyzer.polarity_scores(df2['tweet'][i])[\"pos\"]\n",
    "    neu = analyzer.polarity_scores(df2['tweet'][i])[\"neu\"]\n",
    "    neg = analyzer.polarity_scores(df2['tweet'][i])[\"neg\"]\n",
    "    \n",
    "    scores.append({\"Compound\": compound,\n",
    "                   \"Positive\": pos,\n",
    "                   \"Negative\": neg,\n",
    "                   \"Neutral\": neu\n",
    "                  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to see whats best for own tweets.\n",
    "df2[df2['username']=='cammclean182']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "-https://nealcaren.org/lessons/twint/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import datetime as dt\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "%%time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['username']=='teamknowhowuk']\n",
    "\n",
    "- get last name\n",
    "- plot time of each person replying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Summary code in one block"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "twitter_sentiment_venv",
   "language": "python",
   "name": "twitter_sentiment_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
